{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa1d956d-694f-428c-b673-9f369acc8a00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scripts saved to:\n- /Volumes/edl_dev_ctlg/rawfiles/raw/EDF/dab/create_tables.sql\n- /Volumes/edl_dev_ctlg/rawfiles/raw/EDF/dab/insert_data.sql\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set schemas and volume path\n",
    "catalog = \"edl_dev_ctlg\"\n",
    "source_schema = \"structured\"\n",
    "target_schema = \"structured\"\n",
    "volume_path = \"/Volumes/edl_dev_ctlg/rawfiles/raw/EDF/dab\"\n",
    "table_suffix = \"_c73550\"\n",
    "limit = 100\n",
    "# Get tables\n",
    "tables = [\n",
    "    row.tableName\n",
    "    for row in spark.sql(f\"SHOW TABLES IN {catalog}.{source_schema}\").collect()\n",
    "    if row.tableName.startswith(\"dlt_meta\") and not row.tableName.endswith(table_suffix) \n",
    "]\n",
    "\n",
    "create_statements = []\n",
    "insert_statements = []\n",
    "\n",
    "for table in tables:\n",
    "    full_source_table = f\"{catalog}.{source_schema}.{table}\"\n",
    "    full_target_table = f\"{catalog}.{target_schema}.{table}\"\n",
    "\n",
    "    df = spark.table(full_source_table)\n",
    "    schema = df.schema\n",
    "\n",
    "    columns_def = [\n",
    "        f\"`{field.name}` {field.dataType.simpleString().lower()}\"\n",
    "        for field in schema.fields\n",
    "    ]\n",
    "    columns_sql = \",\\n  \".join(columns_def)\n",
    "\n",
    "    create_sql = f\"\"\"CREATE TABLE IF NOT EXISTS {full_target_table} ({columns_sql});\"\"\"\n",
    "    # insert_sql = f\"\"\"INSERT INTO {full_target_table} SELECT * FROM {full_source_table} limit {limit};\"\"\"\n",
    "\n",
    "    create_statements.append(create_sql)\n",
    "    # -- INSERT INTO ... VALUES\n",
    "    data_rows = df.limit(limit).collect()\n",
    "    if not data_rows:\n",
    "        continue\n",
    "    column_names = [f\"`{f.name}`\" for f in schema.fields]\n",
    "    col_list = \", \".join(column_names)\n",
    "\n",
    "    value_lines = []\n",
    "    for row in data_rows:\n",
    "        values = []\n",
    "        for val in row:\n",
    "            if val is None:\n",
    "                values.append(\"NULL\")\n",
    "            elif isinstance(val, str):\n",
    "                # Escape single quotes\n",
    "                values.append(f\"\"\"'{val.replace(\"'\", \"''\")}'\"\"\")\n",
    "            elif isinstance(val, bool):\n",
    "                values.append(\"TRUE\" if val else \"FALSE\")\n",
    "            else:\n",
    "                values.append(str(val))\n",
    "        value_lines.append(f\"({', '.join(values)})\")\n",
    "\n",
    "    values_sql = \",\\n\".join(value_lines)\n",
    "    insert_sql = f\"\"\"INSERT INTO {full_target_table} ({col_list})VALUES{values_sql};\"\"\"\n",
    "    insert_statements.append(insert_sql)\n",
    "\n",
    "\n",
    "# Combine scripts\n",
    "create_script = \"-- CREATE TABLE SCRIPTS --\\n\\n\" + \"\\n\\n\".join(create_statements)\n",
    "insert_script = \"-- INSERT SCRIPTS --\\n\\n\" + \"\\n\\n\".join(insert_statements)\n",
    "\n",
    "# Write to files in the Volume\n",
    "create_file_path = os.path.join(volume_path, \"create_tables.sql\")\n",
    "insert_file_path = os.path.join(volume_path, \"insert_data.sql\")\n",
    "\n",
    "# Save using Python file write (ensure it's running on Driver)\n",
    "with open(create_file_path, \"w\") as f:\n",
    "    f.write(create_script)\n",
    "\n",
    "with open(insert_file_path, \"w\") as f:\n",
    "    f.write(insert_script)\n",
    "\n",
    "print(f\"✅ Scripts saved to:\\n- {create_file_path}\\n- {insert_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "generate_sql_script",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}